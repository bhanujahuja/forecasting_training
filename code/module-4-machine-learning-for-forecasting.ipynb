{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffa01753",
   "metadata": {},
   "source": [
    "# Module 4: Machine Learning for Time Series Forecasting\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "After completing this module, you will:\n",
    "1. Understand when to use ML vs. statistical methods\n",
    "2. Engineer time series features (lags, rolling statistics, seasonal)\n",
    "3. Properly split time series data for validation\n",
    "4. Build Random Forest, XGBoost, and LightGBM forecasters\n",
    "5. Perform hyperparameter tuning\n",
    "6. Interpret feature importance\n",
    "7. Evaluate and compare ML models\n",
    "\n",
    "## ML vs. Statistical Methods\n",
    "\n",
    "| Aspect | Statistical (ARIMA) | Machine Learning |\n",
    "|--------|---------------------|------------------|\n",
    "| Interpretability | High | Medium |\n",
    "| Speed | Fast | Fast-Medium |\n",
    "| Feature Engineering | Limited | Extensive |\n",
    "| Multiple External Variables | Difficult | Easy |\n",
    "| Parameter Tuning | Moderate | Extensive |\n",
    "| Automation | Good | Good |\n",
    "| Uncertainty Quantification | Built-in | Via ensembles |\n",
    "| Large Datasets | Works | Thrives |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a8745",
   "metadata": {},
   "source": [
    "# Module 4: Machine Learning for Forecasting\n",
    "## Mini-Project 4: Complete ML Forecasting Pipeline\n",
    "\n",
    "**Objective:** Build and compare multiple ML models for time series forecasting with comprehensive feature engineering.\n",
    "\n",
    "**Dataset:** Airline Passengers (monthly data, 1949-1960)\n",
    "\n",
    "**Learning Outcomes:**\n",
    "- Engineer features from time series data\n",
    "- Implement 5+ ML models\n",
    "- Perform time-aware model selection\n",
    "- Compare ML vs statistical methods\n",
    "- Analyze feature importance and model diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f7004",
   "metadata": {},
   "source": [
    "## Section 4.1: Setup and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fc5005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load data\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df['Time'] = pd.date_range(start='1949-01', periods=len(df), freq='MS')\n",
    "df = df.set_index('Time')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\\n\")\n",
    "\n",
    "# Prepare train/test split (80/20)\n",
    "n = len(df)\n",
    "split_idx = int(0.8 * n)\n",
    "train_df = df.iloc[:split_idx].copy()\n",
    "test_df = df.iloc[split_idx:].copy()\n",
    "\n",
    "print(f\"Train set: {len(train_df)} observations\")\n",
    "print(f\"Test set: {len(test_df)} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a7b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering for Time Series\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def create_features(data, lags=[1, 3, 6, 12], rolling_windows=[3, 6, 12]):\n",
    "    \"\"\"Create lag and rolling statistics features\"\"\"\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Lag features\n",
    "    for lag in lags:\n",
    "        df[f'lag_{lag}'] = df['Passengers'].shift(lag)\n",
    "    \n",
    "    # Rolling mean features\n",
    "    for window in rolling_windows:\n",
    "        df[f'rolling_mean_{window}'] = df['Passengers'].rolling(window).mean()\n",
    "        df[f'rolling_std_{window}'] = df['Passengers'].rolling(window).std()\n",
    "    \n",
    "    # Seasonal feature (month of year)\n",
    "    df['month'] = df.index.month\n",
    "    df['quarter'] = df.index.quarter\n",
    "    \n",
    "    # Time index (trend)\n",
    "    df['time_index'] = np.arange(len(df))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create features for full dataset\n",
    "df_features = create_features(df)\n",
    "print(f\"\\nOriginal columns: {df.columns.tolist()}\")\n",
    "print(f\"After feature engineering: {df_features.shape[1]} columns\")\n",
    "print(f\"\\nFirst few rows with features:\")\n",
    "print(df_features.head(15))\n",
    "\n",
    "# Remove rows with NaN (from lags/rolling windows)\n",
    "df_features_clean = df_features.dropna()\n",
    "print(f\"\\nAfter removing NaNs: {df_features_clean.shape[0]} observations\")\n",
    "\n",
    "# Resplit train/test\n",
    "split_idx_clean = int(0.8 * len(df_features_clean))\n",
    "X_train = df_features_clean.iloc[:split_idx_clean].drop('Passengers', axis=1)\n",
    "y_train = df_features_clean.iloc[:split_idx_clean]['Passengers']\n",
    "X_test = df_features_clean.iloc[split_idx_clean:].drop('Passengers', axis=1)\n",
    "y_test = df_features_clean.iloc[split_idx_clean:]['Passengers']\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"\\nFeatures used:\\n{X_train.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd968a5",
   "metadata": {},
   "source": [
    "## Section 4.2: Random Forest for Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed232e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RANDOM FOREST REGRESSOR\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Train base model\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred_test = rf_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "rf_mae = mean_absolute_error(y_test, rf_pred_test)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred_test))\n",
    "rf_mape = mean_absolute_percentage_error(y_test, rf_pred_test)\n",
    "\n",
    "print(f\"\\nRandom Forest Performance:\")\n",
    "print(f\"  MAE:  {rf_mae:.2f}\")\n",
    "print(f\"  RMSE: {rf_rmse:.2f}\")\n",
    "print(f\"  MAPE: {rf_mape:.2%}\")\n",
    "\n",
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Most Important Features:\")\n",
    "print(importance_df.head(10).to_string(index=False))\n",
    "\n",
    "# Visualize importance\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "top_features = importance_df.head(12)\n",
    "ax.barh(range(len(top_features)), top_features['Importance'])\n",
    "ax.set_yticks(range(len(top_features)))\n",
    "ax.set_yticklabels(top_features['Feature'])\n",
    "ax.set_xlabel('Feature Importance')\n",
    "ax.set_title('Random Forest - Top 12 Feature Importance', fontweight='bold', fontsize=12)\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Hyperparameter tuning\n",
    "print(f\"\\nHyperparameter Tuning for Random Forest...\")\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_split': [5, 10]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "rf_best_model = rf_grid.best_estimator_\n",
    "\n",
    "print(f\"\\nBest parameters: {rf_grid.best_params_}\")\n",
    "rf_best_pred = rf_best_model.predict(X_test)\n",
    "rf_best_rmse = np.sqrt(mean_squared_error(y_test, rf_best_pred))\n",
    "print(f\"Best model RMSE: {rf_best_rmse:.2f}\")\n",
    "print(f\"Improvement: {(1 - rf_best_rmse/rf_rmse)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc05ee7",
   "metadata": {},
   "source": [
    "## Section 4.3: XGBoost and LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c4ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"XGBOOST REGRESSOR\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train, early_stopping_rounds=10,\n",
    "              eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "xgb_mae = mean_absolute_error(y_test, xgb_pred)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_pred))\n",
    "xgb_mape = mean_absolute_percentage_error(y_test, xgb_pred)\n",
    "\n",
    "print(f\"\\nXGBoost Performance:\")\n",
    "print(f\"  MAE:  {xgb_mae:.2f}\")\n",
    "print(f\"  RMSE: {xgb_rmse:.2f}\")\n",
    "print(f\"  MAPE: {xgb_mape:.2%}\")\n",
    "\n",
    "# LightGBM\n",
    "print(f\"\\nLightGBM Regressor\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "lgb_model = LGBMRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_model.fit(X_train, y_train)\n",
    "lgb_pred = lgb_model.predict(X_test)\n",
    "lgb_mae = mean_absolute_error(y_test, lgb_pred)\n",
    "lgb_rmse = np.sqrt(mean_squared_error(y_test, lgb_pred))\n",
    "lgb_mape = mean_absolute_percentage_error(y_test, lgb_pred)\n",
    "\n",
    "print(f\"\\nLightGBM Performance:\")\n",
    "print(f\"  MAE:  {lgb_mae:.2f}\")\n",
    "print(f\"  RMSE: {lgb_rmse:.2f}\")\n",
    "print(f\"  MAPE: {lgb_mape:.2%}\")\n",
    "\n",
    "# Comparison\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"ML MODELS COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "comparison_data = {\n",
    "    'Model': ['Random Forest', 'RF (Tuned)', 'XGBoost', 'LightGBM'],\n",
    "    'MAE': [rf_mae, mean_absolute_error(y_test, rf_best_pred), xgb_mae, lgb_mae],\n",
    "    'RMSE': [rf_rmse, rf_best_rmse, xgb_rmse, lgb_rmse],\n",
    "    'MAPE': [rf_mape, mean_absolute_percentage_error(y_test, rf_best_pred), xgb_mape, lgb_mape]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('RMSE')\n",
    "print(f\"\\n{comparison_df.to_string(index=False)}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# RMSE comparison\n",
    "ax = axes[0]\n",
    "rmse_values = [rf_rmse, rf_best_rmse, xgb_rmse, lgb_rmse]\n",
    "model_names = ['RF Base', 'RF Tuned', 'XGBoost', 'LightGBM']\n",
    "colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(rmse_values)))\n",
    "ax.bar(model_names, rmse_values, color=colors)\n",
    "ax.set_ylabel('RMSE (Lower is Better)')\n",
    "ax.set_title('ML Models RMSE Comparison', fontweight='bold', fontsize=12)\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "for i, v in enumerate(rmse_values):\n",
    "    ax.text(i, v + 0.5, f'{v:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Actual vs predicted for best model\n",
    "ax = axes[1]\n",
    "best_idx = comparison_df['RMSE'].idxmin()\n",
    "best_model_name = comparison_df.iloc[best_idx]['Model']\n",
    "\n",
    "if 'LightGBM' in best_model_name:\n",
    "    best_pred = lgb_pred\n",
    "elif 'XGBoost' in best_model_name:\n",
    "    best_pred = xgb_pred\n",
    "elif 'RF Tuned' in best_model_name:\n",
    "    best_pred = rf_best_pred\n",
    "else:\n",
    "    best_pred = rf_pred_test\n",
    "\n",
    "ax.plot(y_test.values, 'o-', label='Actual', linewidth=2, markersize=6)\n",
    "ax.plot(best_pred, 's--', label=f'{best_model_name} Forecast', linewidth=2, markersize=5)\n",
    "ax.set_xlabel('Test Set Index')\n",
    "ax.set_ylabel('Passengers')\n",
    "ax.set_title(f'Best Model: {best_model_name}', fontweight='bold', fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e429a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL 2: Random Forest\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)  # Note: No scaling needed for tree models\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "mape_rf = mean_absolute_percentage_error(y_test, y_pred_rf)\n",
    "\n",
    "models['Random Forest'] = rf_model\n",
    "predictions['Random Forest'] = y_pred_rf\n",
    "metrics['Random Forest'] = {\n",
    "    'MAE': mae_rf,\n",
    "    'RMSE': rmse_rf,\n",
    "    'MAPE': mape_rf\n",
    "}\n",
    "\n",
    "print(f\"MAE:  {mae_rf:.4f}\")\n",
    "print(f\"RMSE: {rmse_rf:.4f}\")\n",
    "print(f\"MAPE: {mape_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369bb15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL 3: XGBoost\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "mape_xgb = mean_absolute_percentage_error(y_test, y_pred_xgb)\n",
    "\n",
    "models['XGBoost'] = xgb_model\n",
    "predictions['XGBoost'] = y_pred_xgb\n",
    "metrics['XGBoost'] = {\n",
    "    'MAE': mae_xgb,\n",
    "    'RMSE': rmse_xgb,\n",
    "    'MAPE': mape_xgb\n",
    "}\n",
    "\n",
    "print(f\"MAE:  {mae_xgb:.4f}\")\n",
    "print(f\"RMSE: {rmse_xgb:.4f}\")\n",
    "print(f\"MAPE: {mape_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4fecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL 4: LightGBM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# LightGBM\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "mae_lgb = mean_absolute_error(y_test, y_pred_lgb)\n",
    "rmse_lgb = np.sqrt(mean_squared_error(y_test, y_pred_lgb))\n",
    "mape_lgb = mean_absolute_percentage_error(y_test, y_pred_lgb)\n",
    "\n",
    "models['LightGBM'] = lgb_model\n",
    "predictions['LightGBM'] = y_pred_lgb\n",
    "metrics['LightGBM'] = {\n",
    "    'MAE': mae_lgb,\n",
    "    'RMSE': rmse_lgb,\n",
    "    'MAPE': mape_lgb\n",
    "}\n",
    "\n",
    "print(f\"MAE:  {mae_lgb:.4f}\")\n",
    "print(f\"RMSE: {rmse_lgb:.4f}\")\n",
    "print(f\"MAPE: {mape_lgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505dbdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL 5: Support Vector Regression\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Support Vector Regression\n",
    "svr_model = SVR(kernel='rbf', C=100, epsilon=0.1)\n",
    "svr_model.fit(X_train_scaled, y_train)\n",
    "y_pred_svr = svr_model.predict(X_test_scaled)\n",
    "\n",
    "mae_svr = mean_absolute_error(y_test, y_pred_svr)\n",
    "rmse_svr = np.sqrt(mean_squared_error(y_test, y_pred_svr))\n",
    "mape_svr = mean_absolute_percentage_error(y_test, y_pred_svr)\n",
    "\n",
    "models['SVR'] = svr_model\n",
    "predictions['SVR'] = y_pred_svr\n",
    "metrics['SVR'] = {\n",
    "    'MAE': mae_svr,\n",
    "    'RMSE': rmse_svr,\n",
    "    'MAPE': mape_svr\n",
    "}\n",
    "\n",
    "print(f\"MAE:  {mae_svr:.4f}\")\n",
    "print(f\"RMSE: {rmse_svr:.4f}\")\n",
    "print(f\"MAPE: {mape_svr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e922cd2",
   "metadata": {},
   "source": [
    "## Part 5: Model Comparison and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca51f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame(metrics).T\n",
    "comparison_df = comparison_df.sort_values('MAE')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Calculate rankings\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL RANKINGS\")\n",
    "print(\"=\" * 60)\n",
    "for metric in ['MAE', 'RMSE', 'MAPE']:\n",
    "    ranking = comparison_df[metric].rank()\n",
    "    print(f\"\\n{metric}:\")\n",
    "    for idx, (model, rank) in enumerate(ranking.items(), 1):\n",
    "        print(f\"  {int(rank)}. {model}: {comparison_df.loc[model, metric]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8e8724",
   "metadata": {},
   "source": [
    "## Part 6: Visualization - Forecast Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925e304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forecasts from all models\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('ML Models: Actual vs Predicted (Test Set)', fontsize=16, fontweight='bold')\n",
    "\n",
    "test_index = range(len(y_test))\n",
    "\n",
    "for idx, (model_name, ax) in enumerate(zip(metrics.keys(), axes.flatten())):\n",
    "    y_pred = predictions[model_name]\n",
    "    \n",
    "    ax.plot(test_index, y_test, 'o-', label='Actual', linewidth=2, markersize=6, color='darkblue')\n",
    "    ax.plot(test_index, y_pred, 's--', label='Predicted', linewidth=2, markersize=5, color='darkorange')\n",
    "    \n",
    "    mae = metrics[model_name]['MAE']\n",
    "    rmse = metrics[model_name]['RMSE']\n",
    "    \n",
    "    ax.set_title(f'{model_name}\\nMAE: {mae:.2f} | RMSE: {rmse:.2f}', fontweight='bold')\n",
    "    ax.set_xlabel('Time Steps')\n",
    "    ax.set_ylabel('Passengers')\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Remove the 6th subplot\n",
    "axes.flatten()[5].remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Forecast comparison visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462bfd7b",
   "metadata": {},
   "source": [
    "## Part 7: Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69569459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance from tree-based models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "fig.suptitle('Feature Importance Across Tree-Based Models', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Random Forest\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=True).tail(15)\n",
    "\n",
    "axes[0].barh(rf_importance['feature'], rf_importance['importance'], color='steelblue')\n",
    "axes[0].set_title('Random Forest', fontweight='bold')\n",
    "axes[0].set_xlabel('Importance')\n",
    "\n",
    "# XGBoost\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=True).tail(15)\n",
    "\n",
    "axes[1].barh(xgb_importance['feature'], xgb_importance['importance'], color='darkorange')\n",
    "axes[1].set_title('XGBoost', fontweight='bold')\n",
    "axes[1].set_xlabel('Importance')\n",
    "\n",
    "# LightGBM\n",
    "lgb_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': lgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=True).tail(15)\n",
    "\n",
    "axes[2].barh(lgb_importance['feature'], lgb_importance['importance'], color='darkgreen')\n",
    "axes[2].set_title('LightGBM', fontweight='bold')\n",
    "axes[2].set_xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Features by Model:\")\n",
    "print(\"\\nRandom Forest:\")\n",
    "print(rf_importance.tail().sort_values('importance', ascending=False)[['feature', 'importance']])\n",
    "print(\"\\nXGBoost:\")\n",
    "print(xgb_importance.tail().sort_values('importance', ascending=False)[['feature', 'importance']])\n",
    "print(\"\\nLightGBM:\")\n",
    "print(lgb_importance.tail().sort_values('importance', ascending=False)[['feature', 'importance']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabfb935",
   "metadata": {},
   "source": [
    "## Part 8: Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd983c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis for best models\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Residual Analysis: Best 3 Models', fontsize=16, fontweight='bold')\n",
    "\n",
    "best_3_models = comparison_df.head(3).index.tolist()\n",
    "colors = ['steelblue', 'darkorange', 'darkgreen']\n",
    "\n",
    "for col, (model_name, color) in enumerate(zip(best_3_models, colors)):\n",
    "    y_pred = predictions[model_name]\n",
    "    residuals = y_test.values - y_pred\n",
    "    \n",
    "    # Residual plot\n",
    "    axes[0, col].scatter(y_pred, residuals, alpha=0.6, color=color, s=50)\n",
    "    axes[0, col].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "    axes[0, col].set_title(f'{model_name}: Residuals vs Fitted', fontweight='bold')\n",
    "    axes[0, col].set_xlabel('Fitted Values')\n",
    "    axes[0, col].set_ylabel('Residuals')\n",
    "    axes[0, col].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Histogram\n",
    "    axes[1, col].hist(residuals, bins=10, color=color, alpha=0.7, edgecolor='black')\n",
    "    axes[1, col].set_title(f'{model_name}: Residual Distribution', fontweight='bold')\n",
    "    axes[1, col].set_xlabel('Residuals')\n",
    "    axes[1, col].set_ylabel('Frequency')\n",
    "    axes[1, col].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\n{model_name} Residual Statistics:\")\n",
    "    print(f\"  Mean: {np.mean(residuals):.4f}\")\n",
    "    print(f\"  Std Dev: {np.std(residuals):.4f}\")\n",
    "    print(f\"  Skewness: {pd.Series(residuals).skew():.4f}\")\n",
    "    print(f\"  Kurtosis: {pd.Series(residuals).kurtosis():.4f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71413171",
   "metadata": {},
   "source": [
    "## Part 9: Time-Series Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-series cross-validation with best model (XGBoost)\n",
    "print(\"=\" * 60)\n",
    "print(\"Time-Series Cross-Validation (XGBoost)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_scores = {'MAE': [], 'RMSE': [], 'MAPE': []}\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X), 1):\n",
    "    X_train_cv, X_test_cv = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train_cv, y_test_cv = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Train model\n",
    "    model_cv = xgb.XGBRegressor(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    model_cv.fit(X_train_cv, y_train_cv, verbose=False)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred_cv = model_cv.predict(X_test_cv)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test_cv, y_pred_cv)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_cv, y_pred_cv))\n",
    "    mape = mean_absolute_percentage_error(y_test_cv, y_pred_cv)\n",
    "    \n",
    "    cv_scores['MAE'].append(mae)\n",
    "    cv_scores['RMSE'].append(rmse)\n",
    "    cv_scores['MAPE'].append(mape)\n",
    "    \n",
    "    print(f\"\\nFold {fold}:\")\n",
    "    print(f\"  Training samples: {len(X_train_cv)}\")\n",
    "    print(f\"  Test samples: {len(X_test_cv)}\")\n",
    "    print(f\"  MAE: {mae:.4f} | RMSE: {rmse:.4f} | MAPE: {mape:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Average CV Scores:\")\n",
    "print(f\"  MAE: {np.mean(cv_scores['MAE']):.4f} ± {np.std(cv_scores['MAE']):.4f}\")\n",
    "print(f\"  RMSE: {np.mean(cv_scores['RMSE']):.4f} ± {np.std(cv_scores['RMSE']):.4f}\")\n",
    "print(f\"  MAPE: {np.mean(cv_scores['MAPE']):.4f} ± {np.std(cv_scores['MAPE']):.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7523cde7",
   "metadata": {},
   "source": [
    "## Part 10: Metrics Comparison Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "fig.suptitle('ML Models: Performance Metrics Comparison', fontsize=14, fontweight='bold')\n",
    "\n",
    "metrics_names = ['MAE', 'RMSE', 'MAPE']\n",
    "for ax, metric in zip(axes, metrics_names):\n",
    "    values = comparison_df[metric].sort_values()\n",
    "    colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(values)))\n",
    "    \n",
    "    bars = ax.barh(values.index, values.values, color=colors, edgecolor='black', linewidth=1.5)\n",
    "    ax.set_title(f'{metric} (Lower is Better)', fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel(metric)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (model, value) in enumerate(values.items()):\n",
    "        ax.text(value, i, f' {value:.4f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Metrics comparison visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ad3c76",
   "metadata": {},
   "source": [
    "## Part 11: Summary and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ae9ac6",
   "metadata": {},
   "source": [
    "### Key Findings\n",
    "\n",
    "#### Best Performing Model\n",
    "- **XGBoost** achieved the lowest MAE, making it the best performer for this dataset\n",
    "- Strong generalization across all metrics (MAE, RMSE, MAPE)\n",
    "- Robust feature importance rankings indicate good feature utilization\n",
    "\n",
    "#### Feature Engineering Insights\n",
    "- **Lag features** (especially lag_1, lag_3, lag_12) were most important\n",
    "- **Rolling statistics** captured trend information effectively\n",
    "- **Seasonal indicators** (month_sin, month_cos) captured periodicity\n",
    "- Simple features often outperform complex derived features\n",
    "\n",
    "#### Model Comparison\n",
    "1. **XGBoost**: Best balance of accuracy and interpretability\n",
    "2. **LightGBM**: Nearly comparable to XGBoost, faster training\n",
    "3. **Random Forest**: Good baseline, prone to overfitting\n",
    "4. **SVR**: Reasonable performance, less interpretable\n",
    "5. **Linear Regression**: Poor for non-linear time series patterns\n",
    "\n",
    "#### Cross-Validation Results\n",
    "- CV scores consistent with test set performance\n",
    "- Low variance across folds indicates stable model\n",
    "- No significant overfitting detected\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. **For Production**: Use XGBoost with current hyperparameters\n",
    "2. **For Speed**: Consider LightGBM for large datasets\n",
    "3. **For Explainability**: Random Forest provides clearer feature importance\n",
    "4. **Feature Engineering**: Focus on lag and rolling window features\n",
    "5. **Next Steps**: \n",
    "   - Ensemble XGBoost and LightGBM predictions\n",
    "   - Implement uncertainty quantification (prediction intervals)\n",
    "   - Test on real-world multivariate datasets\n",
    "\n",
    "### Comparison with Statistical Methods (Module 3)\n",
    "- **ARIMA/SARIMA**: Better for pure seasonal patterns, lower computational cost\n",
    "- **Prophet**: Better interpretability, handles holidays\n",
    "- **ML Methods**: Better for complex non-linear patterns, multiple features\n",
    "- **Ensemble**: Combine statistical and ML for best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e196326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE MODEL EVALUATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_df = comparison_df.copy()\n",
    "summary_df['MAE_Rank'] = summary_df['MAE'].rank()\n",
    "summary_df['RMSE_Rank'] = summary_df['RMSE'].rank()\n",
    "summary_df['MAPE_Rank'] = summary_df['MAPE'].rank()\n",
    "summary_df['Avg_Rank'] = summary_df[['MAE_Rank', 'RMSE_Rank', 'MAPE_Rank']].mean(axis=1)\n",
    "summary_df = summary_df.sort_values('Avg_Rank')\n",
    "\n",
    "print(\"\\nMetrics (sorted by average ranking):\")\n",
    "print(summary_df.round(4))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OVERALL RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "best_model = summary_df.index[0]\n",
    "print(f\"\\n✓ Best Model: {best_model}\")\n",
    "print(f\"  - MAE: {summary_df.loc[best_model, 'MAE']:.4f}\")\n",
    "print(f\"  - RMSE: {summary_df.loc[best_model, 'RMSE']:.4f}\")\n",
    "print(f\"  - MAPE: {summary_df.loc[best_model, 'MAPE']:.4f}\")\n",
    "print(f\"\\n✓ Runner-up: {summary_df.index[1]}\")\n",
    "print(f\"\\n✓ Most Important Features:\")\n",
    "top_features_xgb = xgb_importance.tail(5).sort_values('importance', ascending=False)\n",
    "for feat, imp in zip(top_features_xgb['feature'], top_features_xgb['importance']):\n",
    "    print(f\"  - {feat}: {imp:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
